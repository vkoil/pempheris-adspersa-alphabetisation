{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "---\n",
    "Convert all segments into a feature table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from librosa import feature\n",
    "from spafe.features import lpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000 # sample rate\n",
    "\n",
    "input_data_dir = 'data/segmented/tank/'\n",
    "output_data_dir = 'data/segmented/'\n",
    "\n",
    "ffl = 128 # window size used to compute features\n",
    "fhl = 64 # hop length used to compute features\n",
    "lpcc_order = 10 # order for lpc coffecient filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.706675</td>\n",
       "      <td>-1.572463</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>0.349504</td>\n",
       "      <td>0.372757</td>\n",
       "      <td>0.241634</td>\n",
       "      <td>-0.117264</td>\n",
       "      <td>-0.191146</td>\n",
       "      <td>-0.256805</td>\n",
       "      <td>0.210724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.624871</td>\n",
       "      <td>-1.190540</td>\n",
       "      <td>0.060268</td>\n",
       "      <td>0.065921</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>0.074584</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>-0.049312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.321803</td>\n",
       "      <td>-1.076968</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.016698</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>-0.018862</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>0.043460</td>\n",
       "      <td>-0.035206</td>\n",
       "      <td>0.029091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-19.330162</td>\n",
       "      <td>-0.920781</td>\n",
       "      <td>-0.155204</td>\n",
       "      <td>0.050828</td>\n",
       "      <td>-0.177788</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.073660</td>\n",
       "      <td>-0.023091</td>\n",
       "      <td>0.042130</td>\n",
       "      <td>0.049484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-21.621834</td>\n",
       "      <td>-0.967876</td>\n",
       "      <td>-0.008739</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-0.069026</td>\n",
       "      <td>0.058346</td>\n",
       "      <td>-0.070804</td>\n",
       "      <td>-0.037434</td>\n",
       "      <td>-0.033604</td>\n",
       "      <td>0.151035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-21.601615</td>\n",
       "      <td>-0.986846</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>-0.035704</td>\n",
       "      <td>0.035243</td>\n",
       "      <td>-0.071398</td>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.046528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-22.205381</td>\n",
       "      <td>-0.983458</td>\n",
       "      <td>-0.005896</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>-0.041670</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>-0.040360</td>\n",
       "      <td>-0.028996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-36.043653</td>\n",
       "      <td>-0.988237</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.071427</td>\n",
       "      <td>-0.070589</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.011761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0 -18.706675 -1.572463 -0.026155  0.349504  0.372757  0.241634 -0.117264   \n",
       "1 -17.624871 -1.190540  0.060268  0.065921  0.028515  0.020988  0.074584   \n",
       "2 -19.321803 -1.076968  0.000780  0.016698  0.022658 -0.018862  0.038393   \n",
       "3 -19.330162 -0.920781 -0.155204  0.050828 -0.177788  0.074369  0.073660   \n",
       "4 -21.621834 -0.967876 -0.008739 -0.008102 -0.069026  0.058346 -0.070804   \n",
       "5 -21.601615 -0.986846 -0.000776 -0.001247 -0.001658 -0.035704  0.035243   \n",
       "6 -22.205381 -0.983458 -0.005896  0.001682  0.001211 -0.041670  0.040979   \n",
       "7 -36.043653 -0.988237 -0.000004  0.000838  0.000003 -0.000001  0.071427   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.191146 -0.256805  0.210724  \n",
       "1  0.014129  0.017005 -0.049312  \n",
       "2  0.043460 -0.035206  0.029091  \n",
       "3 -0.023091  0.042130  0.049484  \n",
       "4 -0.037434 -0.033604  0.151035  \n",
       "5 -0.071398  0.034817  0.046528  \n",
       "6  0.083577 -0.040360 -0.028996  \n",
       "7 -0.070589  0.000002  0.011761  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample, _ = librosa.load('data/segmented/tank/67129367.140626174607_10_105.wav', sr=sr)\n",
    "\n",
    "# try:\n",
    "#     a = lpc.lpcc(sig=sample, fs=sr, order=lpcc_order)\n",
    "# except:\n",
    "#     a = np.full(lpcc_order, np.nan)\n",
    "\n",
    "# pd.DataFrame(a).min(axis='rows').tolist()\n",
    "\n",
    "\n",
    "# lpc.lpc(sig=sample, fs=sr, order=lpcc_order )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Feature Table for Clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(output_data_dir, \"segment_features.csv\")):\n",
    "    os.remove(os.path.join(output_data_dir, \"segment_features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vkoil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(columns=[\"file_id\", \"file_len_s\",\n",
    "\"zcr_mean\", \"zcr_std\", \"zcr_max\", \"zcr_min\",\n",
    "\"spc_centroid_mean\", \"spc_centroid_std\", \"spc_centroid_max\", \"spc_centroid_min\",\n",
    "\"spc_bandwidth_mean\", \"spc_bandwidth_std\", \"spc_bandwidth_max\", \"spc_bandwidth_min\",\n",
    "\"spc_contrast_mean\", \"spc_contrast_std\", \"spc_contrast_max\", \"spc_contrast_min\",\n",
    "\"spc_flatness_mean\", \"spc_flatness_std\", \"spc_flatness_max\", \"spc_flatness_min\",\n",
    "\"spc_rolloff_mean\", \"spc_rolloff_std\", \"spc_rolloff_max\", \"spc_rolloff_min\",\n",
    "\"rms_mean\", \"rms_std\", \"rms_max\", \"rms_min\",\n",
    "\"mfcc_0\",\"mfcc_1\",\"mfcc_2\",\"mfcc_3\",\"mfcc_4\",\"mfcc_5\",\"mfcc_6\",\"mfcc_7\",\"mfcc_8\",\"mfcc_9\",\n",
    "\"lpcc_mean_0\",\"lpcc_mean_1\",\"lpcc_mean_2\",\"lpcc_mean_3\",\"lpcc_mean_4\",\"lpcc_mean_5\",\"lpcc_mean_6\",\"lpcc_mean_7\",\"lpcc_mean_8\",\"lpcc_mean_9\",\n",
    "\"lpcc_std_0\",\"lpcc_std_1\",\"lpcc_std_2\",\"lpcc_std_3\",\"lpcc_std_4\",\"lpcc_std_5\",\"lpcc_std_6\",\"lpcc_std_7\",\"lpcc_std_8\",\"lpcc_std_9\",\n",
    "\"lpcc_max_0\",\"lpcc_max_1\",\"lpcc_max_2\",\"lpcc_max_3\",\"lpcc_max_4\",\"lpcc_max_5\",\"lpcc_max_6\",\"lpcc_max_7\",\"lpcc_max_8\",\"lpcc_max_9\",\n",
    "\"lpcc_min_0\",\"lpcc_min_1\",\"lpcc_min_2\",\"lpcc_min_3\",\"lpcc_min_4\",\"lpcc_min_5\",\"lpcc_min_6\",\"lpcc_min_7\",\"lpcc_min_8\",\"lpcc_min_9\",\n",
    "]).to_csv(os.path.join(output_data_dir, \"segment_features.csv\"), index=False, header=True)\n",
    "\n",
    "for f in os.listdir(input_data_dir):\n",
    "    segment, _ = librosa.load(os.path.join(input_data_dir, f), sr=sr)\n",
    "    \n",
    "    zcr = feature.zero_crossing_rate(segment, frame_length=ffl, hop_length=fhl)\n",
    "    spc_centroid = feature.spectral_centroid(y=segment, n_fft=ffl, center=False, sr=sr)\n",
    "    spc_bandwidth = feature.spectral_bandwidth(y=segment, n_fft=ffl, hop_length=fhl, center=False, sr=sr)\n",
    "    spc_contrast = feature.spectral_contrast(y=segment, n_fft=ffl, hop_length=fhl, center=False, sr=sr)\n",
    "    spc_flatness = feature.spectral_flatness(y=segment, n_fft=ffl, hop_length=fhl, center=False)\n",
    "    spc_rolloff = feature.spectral_rolloff(y=segment, n_fft=ffl, hop_length=fhl, center=False, sr=sr)\n",
    "    rms = feature.rms(y=segment, frame_length=ffl, hop_length=fhl)\n",
    "    mfcc = feature.mfcc(y=segment, sr=sr, n_mfcc=10, n_fft=ffl)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        lpcc = lpc.lpcc(sig=segment, fs=sr, order=lpcc_order, win_len=ffl/sr, win_hop=fhl/sr)\n",
    "        lpcc_mean = pd.DataFrame(lpcc).mean(axis='rows').to_list()\n",
    "        lpcc_std = pd.DataFrame(lpcc).std(axis='rows').to_list()\n",
    "        lpcc_max = pd.DataFrame(lpcc).max(axis='rows').to_list()\n",
    "        lpcc_min = pd.DataFrame(lpcc).min(axis='rows').to_list()\n",
    "    except:\n",
    "        lpcc = np.full(lpcc_order, np.nan)\n",
    "        lpcc_mean = pd.DataFrame(lpcc).mean(axis='columns').to_list()\n",
    "        lpcc_std = pd.DataFrame(lpcc).std(axis='columns').to_list()\n",
    "        lpcc_max = pd.DataFrame(lpcc).max(axis='columns').to_list()\n",
    "        lpcc_min = pd.DataFrame(lpcc).min(axis='columns').to_list()\n",
    "\n",
    "\n",
    "    pd.DataFrame([\n",
    "    f,\n",
    "    len(segment)/sr,\n",
    "\n",
    "    np.mean(zcr),\n",
    "    np.std(zcr),\n",
    "    np.max(zcr),\n",
    "    np.min(zcr),\n",
    "\n",
    "    np.mean(spc_centroid),\n",
    "    np.std(spc_centroid),\n",
    "    np.max(spc_centroid),\n",
    "    np.min(spc_centroid),\n",
    "\n",
    "    np.mean(spc_bandwidth),\n",
    "    np.std(spc_bandwidth),\n",
    "    np.max(spc_bandwidth),\n",
    "    np.min(spc_bandwidth),\n",
    "\n",
    "    np.mean(spc_contrast),\n",
    "    np.std(spc_contrast),\n",
    "    np.max(spc_contrast),\n",
    "    np.min(spc_contrast),\n",
    "\n",
    "    np.mean(spc_flatness),\n",
    "    np.std(spc_flatness),\n",
    "    np.max(spc_flatness),\n",
    "    np.min(spc_flatness),\n",
    "\n",
    "    np.mean(spc_rolloff),\n",
    "    np.std(spc_rolloff),\n",
    "    np.max(spc_rolloff),\n",
    "    np.min(spc_rolloff),\n",
    "\n",
    "    np.mean(rms),\n",
    "    np.std(rms),\n",
    "    np.max(rms),\n",
    "    np.min(rms),\n",
    "\n",
    "    np.mean(mfcc[0]),\n",
    "    np.mean(mfcc[1]),\n",
    "    np.mean(mfcc[2]),\n",
    "    np.mean(mfcc[3]),\n",
    "    np.mean(mfcc[4]),\n",
    "    np.mean(mfcc[5]),\n",
    "    np.mean(mfcc[6]),\n",
    "    np.mean(mfcc[7]),\n",
    "    np.mean(mfcc[8]),\n",
    "    np.mean(mfcc[9]),\n",
    "\n",
    "    lpcc_mean[0],\n",
    "    lpcc_mean[1],\n",
    "    lpcc_mean[2],\n",
    "    lpcc_mean[3],\n",
    "    lpcc_mean[4],\n",
    "    lpcc_mean[5],\n",
    "    lpcc_mean[6],\n",
    "    lpcc_mean[7],\n",
    "    lpcc_mean[8],\n",
    "    lpcc_mean[9],\n",
    "\n",
    "    lpcc_std[0],\n",
    "    lpcc_std[1],\n",
    "    lpcc_std[2],\n",
    "    lpcc_std[3],\n",
    "    lpcc_std[4],\n",
    "    lpcc_std[5],\n",
    "    lpcc_std[6],\n",
    "    lpcc_std[7],\n",
    "    lpcc_std[8],\n",
    "    lpcc_std[9],\n",
    "\n",
    "    lpcc_max[0],\n",
    "    lpcc_max[1],\n",
    "    lpcc_max[2],\n",
    "    lpcc_max[3],\n",
    "    lpcc_max[4],\n",
    "    lpcc_max[5],\n",
    "    lpcc_max[6],\n",
    "    lpcc_max[7],\n",
    "    lpcc_max[8],\n",
    "    lpcc_max[9],\n",
    "\n",
    "    lpcc_min[0],\n",
    "    lpcc_min[1],\n",
    "    lpcc_min[2],\n",
    "    lpcc_min[3],\n",
    "    lpcc_min[4],\n",
    "    lpcc_min[5],\n",
    "    lpcc_min[6],\n",
    "    lpcc_min[7],\n",
    "    lpcc_min[8],\n",
    "    lpcc_min[9]\n",
    "    ]).T.to_csv(os.path.join(output_data_dir, \"segment_features.csv\"), index=False, header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(output_data_dir, \"segment_features.csv\")).drop(columns=[\"file_id\", \"file_len_s\"])\n",
    "\n",
    "# assert np.all(np.isfinite(df)) # check if there are any infinite values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(output_data_dir, \"segment_features.csv\"))\n",
    "\n",
    "df.fillna(df.mean(numeric_only=True)).to_csv(os.path.join(output_data_dir, \"segment_features.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30c044526e5b867a9e6fcb8cc6575f33acc42df1bdb3b43eea9f4e61a35fc699"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
